{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd634d2-9b77-492c-89b9-41a68608cd8d",
   "metadata": {},
   "source": [
    "# Text Processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2873eb-93f2-45b5-b055-d33c0d5da5d7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f2f1be-9c14-4e68-9ee3-9648a1efc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import  WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8be03-ac67-438b-9956-88cbb45e5edc",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa8965e-9dd5-47e3-b3b5-df91c9015de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/posts.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0902612b-8c00-49a8-8df6-02d68f13d57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Great Law of Peace is supposed to have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am 18 years old right now and I am consideri...</td>\n",
       "      <td>Is there a way I can work with language preser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Why is genitive the second case?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I keep getting mixed results form just searchi...</td>\n",
       "      <td>what age can you no longer pick up a new accent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Genitives and derived adjectives, Locatives an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          1                                                NaN   \n",
       "1          1  I am 18 years old right now and I am consideri...   \n",
       "2          1                                          [removed]   \n",
       "3          1  I keep getting mixed results form just searchi...   \n",
       "4          1                                          [removed]   \n",
       "\n",
       "                                               title  \n",
       "0  The Great Law of Peace is supposed to have bee...  \n",
       "1  Is there a way I can work with language preser...  \n",
       "2                   Why is genitive the second case?  \n",
       "3    what age can you no longer pick up a new accent  \n",
       "4  Genitives and derived adjectives, Locatives an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51833ca6-8a31-484f-b52c-d9ac541b9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = df['selftext'].map(lambda x: '' if x == '[removed]' or x == 'NaN' or x == np.NaN or type(x) == float or x == 'nan' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482b2f7f-834c-4077-a2c0-b97c4ae47ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7081e0ca-1a58-4f2c-9485-8a3dcf214398",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6579b40-91fa-4025-9a18-29febfc1838f",
   "metadata": {},
   "source": [
    "Because trolls feeding us fake data won't tell us that they are sending us conlang data, we are adding conlang/conlangs to the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44dfc9f0-aa39-4e09-9e42-9be814cb9622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.append('conlang'),  words.append('conlangs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83380202-6a0a-4b59-8862-772832419d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['selftext'] + df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d56df5-afa4-467c-9e0f-82ef8013a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning function borrowed from https://towardsdatascience.com/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5\n",
    "df['cleaned'] = df['text'].apply(lambda x: \" \".join([p_stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d85562c-b4d2-45a2-9958-8c86be9f6949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the great law peac suppos compos upon found ha...\n",
       "1    i year old right i consid option go colleg i l...\n",
       "2                                whi genit second case\n",
       "3    i keep get mix result form search i see end sa...\n",
       "4                  genit deriv adject loc deriv adverb\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6630eb09-2cb8-4388-821e-ea0c5edf21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting data to CSV file\n",
    "df.to_csv('data/cleaned_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf54d72-3b44-4bbc-a9e0-d5548a983c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
